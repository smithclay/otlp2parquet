# otlp2parquet

Universal OpenTelemetry Log Ingestion Pipeline

A Rust-based service that ingests OpenTelemetry logs via OTLP (HTTP/gRPC) and writes them as Parquet files to object storage. Designed to compile to both:

- **WASM** (<3MB compressed) for Cloudflare Workers (free tier)
- **Native binary** for AWS Lambda

## Features

- OTLP HTTP/gRPC endpoint for log ingestion
- ClickHouse-compatible Parquet schema
- Multi-platform support (Cloudflare Workers, AWS Lambda, Standalone)
- Time-based Hive partitioning
- Minimal binary size (<3MB compressed for WASM)
- R2 and S3 storage backends

## Architecture

**Philosophy (Fred Brooks):** "Conceptual integrity is the most important consideration in system design."

The project separates **essence** (OTLPâ†’Parquet conversion) from **accident** (platform I/O). Each platform uses its native idioms:

- **Cloudflare Workers:** Single-threaded JavaScript-style execution (worker crate runtime)
- **Lambda:** Uses lambda_runtime's provided tokio
- **Standalone:** Simple blocking I/O with std::fs and std::net

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Platform-Specific Entry Points         â”‚
â”‚  â”œâ”€ CF Workers: #[event(fetch)]         â”‚
â”‚  â”œâ”€ Lambda: lambda_runtime::run()       â”‚
â”‚  â””â”€ Standalone: blocking HTTP server    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Protocol Layer (TODO)                  â”‚
â”‚  â””â”€ HTTP: POST /v1/logs (protobuf)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Core Processing (PURE - no I/O)       â”‚
â”‚  â”œâ”€ process_otlp_logs(bytes) -> bytes  â”‚
â”‚  â”œâ”€ Parse OTLP protobuf âœ…              â”‚
â”‚  â”œâ”€ Convert to Arrow RecordBatch âœ…     â”‚
â”‚  â”œâ”€ Write Parquet (Snappy) âœ…           â”‚
â”‚  â””â”€ Generate partition path âœ…          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Platform-Specific Storage              â”‚
â”‚  â”œâ”€ R2Storage (async, worker runtime)  â”‚
â”‚  â”œâ”€ S3Storage (async, lambda tokio)    â”‚
â”‚  â””â”€ LocalStorage (blocking, std::fs)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Workspace Structure

```
otlp2parquet/
â”œâ”€â”€ Cargo.toml                # Workspace root
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ otlp2parquet-core/    # âœ… Platform-agnostic logic (PURE)
â”‚   â”‚   â”œâ”€â”€ otlp/             # âœ… OTLPâ†’Arrow conversion
â”‚   â”‚   â”œâ”€â”€ parquet/          # âœ… Parquet writing + partitioning
â”‚   â”‚   â””â”€â”€ schema.rs         # âœ… Arrow schema (15 fields)
â”‚   â”œâ”€â”€ otlp2parquet-runtime/ # ğŸš§ Platform adapters
â”‚   â”‚   â”œâ”€â”€ cloudflare.rs     # âœ… R2Storage (async)
â”‚   â”‚   â”œâ”€â”€ lambda.rs         # âœ… S3Storage (async)
â”‚   â”‚   â””â”€â”€ standalone.rs     # âœ… LocalStorage (blocking)
â”‚   â””â”€â”€ otlp2parquet-proto/   # âœ… Generated protobuf (v1.3.2)
â”‚       â””â”€â”€ proto/            # âœ… OTLP proto files
â””â”€â”€ src/
    â””â”€â”€ main.rs               # âœ… Platform-specific entry points
```

**Note:** No shared Storage trait - each platform uses its native idioms directly.

## Development Setup

### Prerequisites

```bash
# Install Rust toolchain
rustup toolchain install stable
rustup component add rustfmt clippy
rustup target add wasm32-unknown-unknown

# Install wasm-opt (required for WASM optimization)
# macOS:
brew install binaryen

# Linux (Ubuntu/Debian):
sudo apt install binaryen

# Or download from: https://github.com/WebAssembly/binaryen/releases

# Install development tools (optional but recommended)
cargo install twiggy          # WASM binary profiler
curl -LsSf https://astral.sh/uv/install.sh | sh  # uv for Python tools

# Setup pre-commit hooks
uvx pre-commit install
```

### Quick Start with Makefile

```bash
# Show all available commands
make help

# Quick development check (fast)
make dev

# Format and lint
make fmt
make clippy

# Run tests
make test

# Build for specific platform
make build-standalone
make build-lambda
make build-cloudflare

# Full WASM pipeline: build â†’ optimize â†’ compress â†’ profile
make wasm-full
```

## Building

### Using Makefile (Recommended)

```bash
# Cloudflare Workers - full WASM pipeline
make wasm-full

# AWS Lambda
make build-lambda

# Standalone server
make build-standalone

# Run pre-commit checks before committing
make pre-commit

# Run full CI locally
make ci
```

### Manual Build Commands

#### Cloudflare Workers (WASM)

```bash
# Build with minimal features
cargo build --release \
  --target wasm32-unknown-unknown \
  --no-default-features \
  --features cloudflare

# Optimize
wasm-opt -Oz --enable-bulk-memory --enable-nontrapping-float-to-int \
  -o optimized.wasm target/wasm32-unknown-unknown/release/otlp2parquet.wasm

# Compress
gzip -9 optimized.wasm

# Check size (must be <3MB)
ls -lh optimized.wasm.gz
```

#### AWS Lambda

```bash
# Install cargo-lambda (optional, for local testing)
cargo install cargo-lambda

# Build
cargo build --release --no-default-features --features lambda

# Or with gRPC support
cargo build --release --no-default-features --features lambda,grpc
```

#### Standalone (Development)

```bash
cargo build --release --no-default-features --features standalone
./target/release/otlp2parquet
```

## Development Status

**Current Phase:** Core Implementation Complete

### âœ… Completed (Phase 1-2)

- [x] Workspace structure created
- [x] Cargo.toml with size optimizations
- [x] Arrow schema definition (15 fields, ClickHouse-compatible)
- [x] OTLP protobuf integration (v1.3.2, code generation configured)
- [x] OTLP â†’ Arrow conversion (ArrowConverter with all fields)
- [x] Parquet writer implementation (Snappy compression, minimal features)
- [x] Partition path generation (Hive-style time partitioning)
- [x] Platform-specific storage implementations (R2, S3, Local)
- [x] Brooks architecture refactor (pure core, platform-native runtimes)
- [x] Core processing function (`process_otlp_logs`)
- [x] CI/CD with protoc installation
- [x] Pre-commit hooks (fmt, clippy)

### ğŸš§ In Progress (Phase 3-4)

- [ ] HTTP protocol handlers
- [ ] Cloudflare Workers entry point (`#[event(fetch)]`)
- [ ] Lambda handler implementation
- [ ] Standalone HTTP server

### ğŸ“‹ Planned (Phase 5)

- [ ] Binary size optimization and profiling
- [ ] End-to-end integration tests
- [ ] Load testing
- [ ] Deployment configurations

See [CLAUDE.md](./CLAUDE.md) for detailed implementation instructions.

## Size Optimization

Target: <3MB compressed WASM

Current optimizations:
- `opt-level = "z"` (size optimization)
- LTO enabled
- `default-features = false` for all dependencies
- Minimal feature flags
- Snappy compression only
- Strip symbols

## Schema

ClickHouse-compatible schema with PascalCase naming:

- Timestamps (Timestamp, ObservedTimestamp)
- Trace context (TraceId, SpanId, TraceFlags)
- Severity (SeverityText, SeverityNumber)
- Body
- Extracted attributes (ServiceName, ServiceNamespace, ServiceInstanceId)
- Scope (ScopeName, ScopeVersion)
- Maps (ResourceAttributes, LogAttributes)

## License

MIT OR Apache-2.0
